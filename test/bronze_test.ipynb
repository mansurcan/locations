{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Bronze layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 10:31:39 WARN Utils: Your hostname, Mansurs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.24 instead (on interface en0)\n",
      "24/03/14 10:31:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/Cellar/apache-spark/3.5.1/libexec/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/mansurcan/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/mansurcan/.ivy2/jars\n",
      "com.crealytics#spark-excel_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9c141e14-b00f-4a64-854d-f9cf6be37f5d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.crealytics#spark-excel_2.12;0.13.1 in central\n",
      "\tfound org.apache.poi#poi;4.1.0 in central\n",
      "\tfound commons-codec#commons-codec;1.12 in central\n",
      "\tfound org.apache.commons#commons-collections4;4.3 in central\n",
      "\tfound org.apache.commons#commons-math3;3.6.1 in central\n",
      "\tfound org.apache.poi#poi-ooxml;4.1.0 in central\n",
      "\tfound org.apache.poi#poi-ooxml-schemas;4.1.0 in central\n",
      "\tfound org.apache.xmlbeans#xmlbeans;3.1.0 in central\n",
      "\tfound com.github.virtuald#curvesapi;1.06 in central\n",
      "\tfound com.norbitltd#spoiwo_2.12;1.6.0 in central\n",
      "\tfound org.scala-lang.modules#scala-xml_2.12;1.2.0 in central\n",
      "\tfound joda-time#joda-time;2.9.9 in central\n",
      "\tfound org.joda#joda-convert;2.0.1 in central\n",
      "\tfound com.monitorjbl#xlsx-streamer;2.1.0 in central\n",
      "\tfound com.rackspace.apache#xerces2-xsd11;2.11.1 in central\n",
      "\tfound com.rackspace.eclipse.webtools.sourceediting#org.eclipse.wst.xml.xpath2.processor;2.1.100 in central\n",
      "\tfound edu.princeton.cup#java-cup;10k in central\n",
      "\tfound com.ibm.icu#icu4j;4.6 in central\n",
      "\tfound xml-resolver#xml-resolver;1.2 in central\n",
      "\tfound xml-apis#xml-apis;1.4.01 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.25 in central\n",
      "\tfound org.apache.commons#commons-compress;1.19 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.8.8 in central\n",
      ":: resolution report :: resolve 571ms :: artifacts dl 21ms\n",
      "\t:: modules in use:\n",
      "\tcom.crealytics#spark-excel_2.12;0.13.1 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.8.8 from central in [default]\n",
      "\tcom.github.virtuald#curvesapi;1.06 from central in [default]\n",
      "\tcom.ibm.icu#icu4j;4.6 from central in [default]\n",
      "\tcom.monitorjbl#xlsx-streamer;2.1.0 from central in [default]\n",
      "\tcom.norbitltd#spoiwo_2.12;1.6.0 from central in [default]\n",
      "\tcom.rackspace.apache#xerces2-xsd11;2.11.1 from central in [default]\n",
      "\tcom.rackspace.eclipse.webtools.sourceediting#org.eclipse.wst.xml.xpath2.processor;2.1.100 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.12 from central in [default]\n",
      "\tedu.princeton.cup#java-cup;10k from central in [default]\n",
      "\tjoda-time#joda-time;2.9.9 from central in [default]\n",
      "\torg.apache.commons#commons-collections4;4.3 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.19 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.6.1 from central in [default]\n",
      "\torg.apache.poi#poi;4.1.0 from central in [default]\n",
      "\torg.apache.poi#poi-ooxml;4.1.0 from central in [default]\n",
      "\torg.apache.poi#poi-ooxml-schemas;4.1.0 from central in [default]\n",
      "\torg.apache.xmlbeans#xmlbeans;3.1.0 from central in [default]\n",
      "\torg.joda#joda-convert;2.0.1 from central in [default]\n",
      "\torg.scala-lang.modules#scala-xml_2.12;1.2.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.25 from central in [default]\n",
      "\txml-apis#xml-apis;1.4.01 from central in [default]\n",
      "\txml-resolver#xml-resolver;1.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.apache.commons#commons-compress;1.18 by [org.apache.commons#commons-compress;1.19] in [default]\n",
      "\torg.apache.poi#poi;4.0.0 by [org.apache.poi#poi;4.1.0] in [default]\n",
      "\torg.apache.poi#poi-ooxml;4.0.0 by [org.apache.poi#poi-ooxml;4.1.0] in [default]\n",
      "\torg.apache.poi#poi-ooxml-schemas;4.0.0 by [org.apache.poi#poi-ooxml-schemas;4.1.0] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   27  |   0   |   0   |   4   ||   23  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9c141e14-b00f-4a64-854d-f9cf6be37f5d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 23 already retrieved (0kB/11ms)\n",
      "24/03/14 10:31:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/14 10:31:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/03/14 10:31:42 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/03/14 10:31:42 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/03/14 10:31:42 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "24/03/14 10:31:42 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "24/03/14 10:31:42 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "24/03/14 10:31:42 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
      "24/03/14 10:31:42 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n",
      "2024-03-14 10:31:44,827: INFO: Spark session initialized for test class.\n",
      "2024-03-14 10:31:44,829: INFO: Bronze directory set to: /Users/mansurcan/Documents/ITC/Lloyds/test/../Bronze, with files: ['locations.xlsx', 'NSP21CL_AUG23_UK_LU.csv', 'NSPL21_AUG_2023_UK.csv']\n",
      "test_read_bronze_files (__main__.SparkDataTests.test_read_bronze_files) ... 2024-03-14 10:31:44,830: INFO: Starting test: test_read_bronze_files\n",
      "2024-03-14 10:31:44,831: INFO: Processing file: locations.xlsx\n",
      "2024-03-14 10:31:51,088: INFO: File locations.xlsx passed with 1592 records.\n",
      "2024-03-14 10:31:51,089: INFO: Processing file: NSP21CL_AUG23_UK_LU.csv\n",
      "2024-03-14 10:31:54,987: INFO: File NSP21CL_AUG23_UK_LU.csv passed with 2694205 records.\n",
      "2024-03-14 10:31:54,987: INFO: Processing file: NSPL21_AUG_2023_UK.csv\n",
      "2024-03-14 10:31:56,344: INFO: File NSPL21_AUG_2023_UK.csv passed with 2694205 records.\n",
      "ok\n",
      "test_schema_validation (__main__.SparkDataTests.test_schema_validation) ... 2024-03-14 10:31:56,347: INFO: Starting test: test_schema_validation\n",
      "2024-03-14 10:31:56,426: INFO: Schema validation passed.\n",
      "ok\n",
      "2024-03-14 10:31:56,995: INFO: Spark session stopped.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 19.830s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Configure logging to display more details\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s: %(levelname)s: %(message)s')\n",
    "\n",
    "class SparkDataTests(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        # Initialize Spark Session\n",
    "        cls.spark = SparkSession.builder \\\n",
    "            .appName(\"Data Pipeline Testing - Bronze Layer\") \\\n",
    "            .config(\"spark.jars.packages\", \"com.crealytics:spark-excel_2.12:0.13.1\") \\\n",
    "            .getOrCreate()\n",
    "        logging.info(\"Spark session initialized for test class.\")\n",
    "\n",
    "        # Directories and file names setup\n",
    "        cls.current_dir = os.getcwd()\n",
    "        cls.lloyds_dir = os.path.join(cls.current_dir, '..')\n",
    "        cls.bronze_dir = os.path.join(cls.lloyds_dir, 'Bronze')\n",
    "        cls.files = [\"locations.xlsx\", \"NSP21CL_AUG23_UK_LU.csv\", \"NSPL21_AUG_2023_UK.csv\"]\n",
    "        logging.info(f\"Bronze directory set to: {cls.bronze_dir}, with files: {cls.files}\")\n",
    "\n",
    "    def test_read_bronze_files(self):\n",
    "        logging.info(\"Starting test: test_read_bronze_files\")\n",
    "        for file_name in self.files:\n",
    "            file_path = os.path.join(self.bronze_dir, file_name)\n",
    "            logging.info(f\"Processing file: {file_name}\")\n",
    "            if file_name.endswith('.csv'):\n",
    "                df = self.spark.read.csv(file_path, header=True)\n",
    "            elif file_name.endswith('.xlsx'):\n",
    "                df = self.spark.read.format(\"com.crealytics.spark.excel\") \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .load(file_path)\n",
    "\n",
    "            self.assertIsNotNone(df, f\"DataFrame for {file_name} should not be None\")\n",
    "            record_count = df.count()\n",
    "            self.assertGreater(record_count, 0, f\"DataFrame for {file_name} should not be empty\")\n",
    "            logging.info(f\"File {file_name} passed with {record_count} records.\")\n",
    "\n",
    "    def test_schema_validation(self):\n",
    "        logging.info(\"Starting test: test_schema_validation\")\n",
    "        expected_schema = StructType([\n",
    "            StructField(\"LocationId\", StringType(), True),\n",
    "            StructField(\"OrganisationID\", StringType(), True),\n",
    "            StructField(\"LocationPostCode\", StringType(), True),\n",
    "        ])\n",
    "\n",
    "        df_test = self.spark.read \\\n",
    "            .format(\"com.crealytics.spark.excel\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .schema(expected_schema) \\\n",
    "            .load(os.path.join(self.bronze_dir, \"locations.xlsx\"))\n",
    "\n",
    "        self.assertEqual(df_test.schema, expected_schema, \"Schema does not match the expected schema\")\n",
    "        logging.info(\"Schema validation passed.\")\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        cls.spark.stop()\n",
    "        logging.info(\"Spark session stopped.\")\n",
    "\n",
    "# Define a main function to run the tests with enhanced output\n",
    "def run_tests():\n",
    "    # Create a test suite\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(SparkDataTests)\n",
    "    # Run the test suite with a runner that provides a higher verbosity level\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(suite)\n",
    "\n",
    "# Execute the tests\n",
    "run_tests()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
